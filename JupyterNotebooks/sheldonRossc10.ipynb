{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import string\r\n",
    "import calendar\r\n",
    "import re\r\n",
    "import math\r\n",
    "import sympy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pprint\r\n",
    "\r\n",
    "from fractions import Fraction\r\n",
    "from scipy import stats\r\n",
    "from scipy import special\r\n",
    "\r\n",
    "\r\n",
    "print(f\"numpy version is {np.__version__}\")\r\n",
    "print(f\"pandas version is {pd.__version__}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numpy version is 1.20.3\n",
      "pandas version is 1.3.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# def getDiscreteProbsExpon(input_ranges):\r\n",
    "#     prob_out = []\r\n",
    "#     for i in input_ranges:\r\n",
    "#         if i[0] == '<':\r\n",
    "#            high = float(i[1:])\r\n",
    "#             prob_out.append(stats.expon.cdf(high, scale ))\r\n",
    "#         elif i[0] == '>':\r\n",
    "#             low = float(i[1:])\r\n",
    "#             prob_out.append(1 - stats.expon.cdf(low, scale ))\r\n",
    "#         else:\r\n",
    "#             low, high = i.split('-')\r\n",
    "#             prob_out.append(stats.expon.cdf(float(high), scale ) - stats.expon.cdf(float(low), scale ))\r\n",
    "#     return np.array(prob_out)\r\n",
    "\r\n",
    "# def getDiscreteProbsPoisson(input_ranges):\r\n",
    "#     prob_out = []\r\n",
    "#     for i in input_ranges:\r\n",
    "#         if i[0] == '<':\r\n",
    "#             high = float(i[1:])\r\n",
    "#             prob_out.append(stats.poisson.cdf(high))\r\n",
    "#         elif i[0] == '>':\r\n",
    "#             low = float(i[1:])\r\n",
    "#             prob_out.append(1 - stats.poisson.cdf(low))\r\n",
    "#         elif len(i.split('-')) == 2:\r\n",
    "#             low, high = i.split('-')\r\n",
    "#             prob_out.append(stats.poisson.cdf(float(high)) - stats.poisson.cdf(float(low)))\r\n",
    "#         else:\r\n",
    "#             prob_out.append(stats.poisson.pmf(float(i)))\r\n",
    "#     return np.array(prob_out)\r\n",
    "\r\n",
    "def getDiscreteProbs_PMF(in_dist, input_ranges):\r\n",
    "    prob_out = []\r\n",
    "    for i in input_ranges:\r\n",
    "        if i[0] == '<':\r\n",
    "            high = float(i[1:])\r\n",
    "            prob_out.append(in_dist.cdf(high))\r\n",
    "        elif i[0] == '>':\r\n",
    "            low = float(i[1:])\r\n",
    "            prob_out.append(1 - in_dist.cdf(low))\r\n",
    "        elif len(i.split('-')) == 2:\r\n",
    "            low, high = i.split('-')\r\n",
    "            prob_out.append(in_dist.cdf(float(high)) - in_dist.cdf(float(low)))\r\n",
    "        else:\r\n",
    "            prob_out.append(in_dist.pmf(float(i)))\r\n",
    "    return np.array(prob_out)\r\n",
    "\r\n",
    "\r\n",
    "def getDiscreteProbs_PDF(in_dist, input_ranges):\r\n",
    "    prob_out = []\r\n",
    "    for i in input_ranges:\r\n",
    "        \r\n",
    "        if i[0] == '<':\r\n",
    "            high = float(i[1:])\r\n",
    "            prob_out.append(in_dist.cdf(high))\r\n",
    "            \r\n",
    "        elif i[0] == '>':\r\n",
    "            low = float(i[1:])\r\n",
    "            prob_out.append(1 - in_dist.cdf(low))\r\n",
    "            \r\n",
    "        elif len(i.split('-')) == 2:\r\n",
    "            low, high = i.split('-')\r\n",
    "            prob_out.append(in_dist.cdf(float(high)) - in_dist.cdf(float(low)))\r\n",
    "            \r\n",
    "    return np.array(prob_out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Monte Carlo simulation for p-value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def getPVal_MCSIM(prob_in, nRuns, sampleSize):\r\n",
    "    ani_rng             = np.random.default_rng()\r\n",
    "    all_TS = []\r\n",
    "    for i in range(nRuns):\r\n",
    "        oneSample       = ani_rng.choice(prob.shape[0], p = prob_in, size = (sampleSize, 1))\r\n",
    "        a, b            = np.unique(oneSample, return_counts = True)\r\n",
    "        testStat        = -sampleSize + np.divide((b ** 2) , sampleSize * prob_in).sum()\r\n",
    "        all_TS.append(testStat)\r\n",
    "    return all_TS"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Goodness of fit test with all parameters specified"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# manual data entry\r\n",
    "\r\n",
    "# prob        = np.array([1/4, 1/2, 1/4])\r\n",
    "# names       = ['White', 'Pink', \"Red\"]\r\n",
    "# X           = np.array([141, 291, 132])\r\n",
    "\r\n",
    "# read data from text file\r\n",
    "# two-column data\r\n",
    "\r\n",
    "rawData     = np.loadtxt('GOF_test_specified.txt', dtype = ('str', 'str'), delimiter= ' ')\r\n",
    "\r\n",
    "# four-column data\r\n",
    "# rawData     = np.loadtxt('GOF_test_specified.txt', delimiter= ' ')\r\n",
    "# rawData     = np.sort(rawData.reshape((-1, 2)), axis = 0)\r\n",
    "\r\n",
    "names       = np.squeeze(rawData[:, 0]).astype(str)\r\n",
    "X           = np.squeeze(rawData[:, 1]).astype(int)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# probabilities of the assumed distribution function\r\n",
    "\r\n",
    "# Uniform\r\n",
    "# prob        = (np.ones(X.shape[0]) * 1/X.shape[0]).round(4)\r\n",
    "\r\n",
    "# Poisson\r\n",
    "# poisMean = 0.3\r\n",
    "# prob = getDiscreteProbsPoisson(names, poisMean)\r\n",
    "\r\n",
    "# Exponential\r\n",
    "# exponMean   = 50\r\n",
    "# prob        = getDiscreteProbsExpon(names, exponMean)\r\n",
    "\r\n",
    "# discrete probaiblity distribution\r\n",
    "ani_prob    = stats.poisson(mu = 4)\r\n",
    "prob        = getDiscreteProbs_PMF(ani_prob, names)\r\n",
    "\r\n",
    "# continuous probaiblity distribution\r\n",
    "\r\n",
    "# ani_prob    = stats.norm(loc = 100, scale = 15)\r\n",
    "# prob        = getDiscreteProbs_PDF(ani_prob, names)\r\n",
    "\r\n",
    "sig         = 5\r\n",
    "n           = X.sum()\r\n",
    "k           = prob.shape[0]\r\n",
    "\r\n",
    "testStat    = -n + np.divide((X ** 2) , n * prob).sum()\r\n",
    "\r\n",
    "# chi-squared approximation to find p value\r\n",
    "pVal        = 1 - stats.chi2.cdf(testStat, k - 1)\r\n",
    "\r\n",
    "# MC simulations to find p-value\r\n",
    "# mc_runs     = 100000\r\n",
    "# sample_Size = n\r\n",
    "# all_TS      = np.array(getPVal_MCSIM(prob, mc_runs, sample_Size))\r\n",
    "# n_smaller   = all_TS[all_TS > testStat]\r\n",
    "# pVal        = n_smaller.shape[0] / all_TS.shape[0]\r\n",
    "\r\n",
    "hypo        = 'rejected' if pVal < (0.01 * sig) else 'accepted'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### output as table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "outDict     ={'Test Statistic'              : '{:.2e}'.format(testStat),\r\n",
    "            '$p$ value \\%'                  : '{:.2f}'.format(100 * pVal),\r\n",
    "            'Significance ($\\\\alpha$) \\%'   : '{:.2f}'.format(sig),\r\n",
    "            'null hypothesis ($H_0$)'       : hypo,\r\n",
    "            'minimum $n p_i$'               : '{:.0f}'.format(min(np.multiply(prob, n)))\r\n",
    "            }\r\n",
    "dfb = pd.DataFrame.from_dict(outDict, orient='index', columns = ['Value'])\r\n",
    "\r\n",
    "df                      = pd.DataFrame(np.vstack((X.astype(str), prob.round(4))).T, columns= ['$X_i$', '$p_i$'], index=names)\r\n",
    "df                      = df.append(pd.Series({'$X_i$' : n, '$p_i$' : 1}, name = 'Total'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "s3          = df.to_latex(escape=False, column_format='@{}lrr@{}')\r\n",
    "s3          = s3.replace('Total', '\\midrule\\nTotal')\r\n",
    "s3          = s3.replace('{} &', 'Grade &')\r\n",
    "s4          = dfb.to_latex(escape=False, column_format='@{}lr@{}')\r\n",
    "s4          = s4.replace('{} &     Value', '\\multicolumn{2}{c}{\\\\texttt{Goodness of Fit Test}}')\r\n",
    "\r\n",
    "print('\\\\begin{table}[H]')\r\n",
    "print('\\\\centering')\r\n",
    "print('\\\\begin{minipage}{0.4\\\\textwidth}')\r\n",
    "print('\\\\centering')\r\n",
    "print(s3)\r\n",
    "print('\\\\end{minipage}')\r\n",
    "print('\\\\begin{minipage}{0.4\\\\textwidth}')\r\n",
    "print('\\\\centering')\r\n",
    "print(s4)\r\n",
    "print('\\\\end{minipage}')\r\n",
    "print('\\\\end{table}')\r\n",
    "print('\\\\bigskip')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{minipage}{0.4\\textwidth}\n",
      "\\centering\n",
      "\\begin{tabular}{@{}lrr@{}}\n",
      "\\toprule\n",
      "Grade & $X_i$ &   $p_i$ \\\\\n",
      "\\midrule\n",
      "0     &     0 &  0.0183 \\\\\n",
      "1     &     5 &  0.0733 \\\\\n",
      "2     &    22 &  0.1465 \\\\\n",
      "3     &    23 &  0.1954 \\\\\n",
      "4     &    32 &  0.1954 \\\\\n",
      "5     &    22 &  0.1563 \\\\\n",
      "6     &    19 &  0.1042 \\\\\n",
      "7     &    13 &  0.0595 \\\\\n",
      "8     &     6 &  0.0298 \\\\\n",
      "9     &     4 &  0.0132 \\\\\n",
      "10    &     4 &  0.0053 \\\\\n",
      "11    &     0 &  0.0019 \\\\\n",
      "\\midrule\n",
      "Total &   150 &       1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{minipage}\n",
      "\\begin{minipage}{0.4\\textwidth}\n",
      "\\centering\n",
      "\\begin{tabular}{@{}lr@{}}\n",
      "\\toprule\n",
      "\\multicolumn{2}{c}{\\texttt{Goodness of Fit Test}} \\\\\n",
      "\\midrule\n",
      "Test Statistic             &  2.62e+01 \\\\\n",
      "$p$ value \\%               &      0.60 \\\\\n",
      "Significance ($\\alpha$) \\% &      5.00 \\\\\n",
      "null hypothesis ($H_0$)    &  rejected \\\\\n",
      "minimum $n p_i$            &         0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{minipage}\n",
      "\\end{table}\n",
      "\\bigskip\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contingency tables test of independence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sig                 = 5\r\n",
    "\r\n",
    "conTab              = pd.read_csv('Con_table.txt', sep=',', index_col=0)\r\n",
    "r, s                = conTab.shape[0], conTab.shape[1]\r\n",
    "N_ij                = conTab.copy()\r\n",
    "\r\n",
    "print(conTab)\r\n",
    "\r\n",
    "conTab['Row Sum']   = conTab.sum(axis = 1)\r\n",
    "conTab.loc['Total'] = conTab.sum()\r\n",
    "n                   = int(conTab['Row Sum'][-1])\r\n",
    "\r\n",
    "p                   = conTab['Row Sum'][:-1] / n\r\n",
    "q_series            = conTab.loc['Total']\r\n",
    "q                   = q_series[:-1] / q_series[-1]\r\n",
    "\r\n",
    "p_arr               = np.tile(p, (s, 1)).T\r\n",
    "q_arr               = np.tile(q, (r, 1))\r\n",
    "\r\n",
    "T_con               = -n + (np.divide(N_ij ** 2, n * np.multiply(p_arr, q_arr))).to_numpy().sum()\r\n",
    "p_con               = 1 - stats.chi2.cdf(T_con, (r-1)*(s-1))\r\n",
    "hypo                = 'rejected' if p_con < (0.01 * sig) else 'accepted'\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  Observations   Rain\n",
      "Sky Color                            \n",
      "Red                         61     26\n",
      "Mainly red                 194     52\n",
      "Yellow                     159     81\n",
      "Mainly yellow              188     86\n",
      "Red and yellow             194     52\n",
      "Gray                       302    167\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### output contingency table and summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "outDict     ={'X levels ($r$)'              : '{:d}'.format(r),\r\n",
    "            'Y levels ($s$)'                : '{:d}'.format(s),\r\n",
    "            'Data points ($n$)'             : '{:d}'.format(n),\r\n",
    "            'Test Statistic'                : '{:.2e}'.format(T_con),\r\n",
    "            '$p$ value \\%'                  : '{:.2f}'.format(100 * p_con),\r\n",
    "            'Significance ($\\\\alpha$) \\%'   : '{:.2f}'.format(sig),\r\n",
    "            'null hypothesis ($H_0$)'       : hypo\r\n",
    "            }\r\n",
    "dfc = pd.DataFrame.from_dict(outDict, orient='index', columns = ['Value'])\r\n",
    "\r\n",
    "# df                      = pd.DataFrame(np.vstack((X.astype(str), prob.round(4))).T, columns= ['$X_i$', '$p_i$'], index=names)\r\n",
    "# df                      = df.append(pd.Series({'$X_i$' : n, '$p_i$' : 1}, name = 'Total'))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "s6          = dfc.to_latex(escape=False, column_format='@{}lr@{}')\r\n",
    "s6          = s6.replace('{} &     Value', '\\multicolumn{2}{c}{\\\\texttt{Contingency Table Independence}}')\r\n",
    "\r\n",
    "s5          = conTab.to_latex()\r\n",
    "s5          = s5.replace('Total', '\\midrule\\nTotal')\r\n",
    "\r\n",
    "\r\n",
    "print('\\\\begin{table}[H]')\r\n",
    "print('\\\\centering')\r\n",
    "print(s5)\r\n",
    "print('\\\\end{table}')\r\n",
    "\r\n",
    "print('\\\\bigskip')\r\n",
    "\r\n",
    "print('\\\\begin{table}[H]')\r\n",
    "print('\\\\centering')\r\n",
    "print(s6)\r\n",
    "print('\\\\end{table}')\r\n",
    "\r\n",
    "print('\\\\bigskip')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &   Observations &   Rain &  Row Sum \\\\\n",
      "Sky Color       &                &        &          \\\\\n",
      "\\midrule\n",
      "Red             &             61 &     26 &       87 \\\\\n",
      "Mainly red      &            194 &     52 &      246 \\\\\n",
      "Yellow          &            159 &     81 &      240 \\\\\n",
      "Mainly yellow   &            188 &     86 &      274 \\\\\n",
      "Red and yellow  &            194 &     52 &      246 \\\\\n",
      "Gray            &            302 &    167 &      469 \\\\\n",
      "\\midrule\n",
      "Total           &           1098 &    464 &     1562 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{table}\n",
      "\\bigskip\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{@{}lr@{}}\n",
      "\\toprule\n",
      "\\multicolumn{2}{c}{\\texttt{Contingency Table Independence}} \\\\\n",
      "\\midrule\n",
      "X levels ($r$)             &         6 \\\\\n",
      "Y levels ($s$)             &         2 \\\\\n",
      "Data points ($n$)          &      1562 \\\\\n",
      "Test Statistic             &  2.74e+01 \\\\\n",
      "$p$ value \\%               &      0.00 \\\\\n",
      "Significance ($\\alpha$) \\% &      5.00 \\\\\n",
      "null hypothesis ($H_0$)    &  rejected \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{table}\n",
      "\\bigskip\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kolmogorov-Smirnov test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "raw             = np.sort(np.loadtxt('KS_test.txt', delimiter=','))\r\n",
    "\r\n",
    "def empirical_CDF(x_in, obs_in):\r\n",
    "    return ((obs_in <= x_in).sum()) / obs_in.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16720/2798809113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mraw\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "norm_ex     = stats.norm(loc = 3, scale = 4)\r\n",
    "stats.kstest((np.log(raw) - 3) / 4, 'norm')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.43163234117636107, pvalue=0.015081277352786637)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}